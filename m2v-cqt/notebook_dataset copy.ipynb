{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circshift dataset length: 136248\n",
      "Regular dataset length: 1622\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataset_classes.DEAM_CQT_circshift import *\n",
    "from dataset_classes.DEAM_CQT import *\n",
    "\n",
    "annot_path = \"deam_dataset/DEAM_Annotations/annotations/annotations averaged per song/dynamic (per second annotations)/arousal.csv\"\n",
    "audio_path = \"deam_dataset/DEAM_audio/MEMD_audio/\"\n",
    "transform_path = \"transforms/\"\n",
    "transform_name = \"cqt\"\n",
    "circshift_dataset = DEAM_CQT_Dataset_With_CircShift(annot_path=annot_path, audio_path=audio_path, save_files=True, transform_path=transform_path, transform_name=transform_name, train=True)\n",
    "circshift_loader = torch.utils.data.DataLoader(dataset=circshift_dataset, batch_size=1, shuffle=True)\n",
    "train_dataset = DEAM_CQT_Dataset(annot_path=annot_path, audio_path=audio_path, save_files=True, transform_path=transform_path, transform_name=transform_name, train=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "print(\"Circshift dataset length:\", circshift_loader.__len__())\n",
    "print(\"Regular dataset length:\", train_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2615, -0.2612, -0.1466, -0.1006, -0.0738, -0.0949, -0.1174, -0.1263,\n",
      "        -0.1357, -0.1411, -0.1408, -0.1473, -0.1691, -0.2920, -0.2984, -0.3051,\n",
      "        -0.3207, -0.3254, -0.3269, -0.3276, -0.3256, -0.3177, -0.3120, -0.3077,\n",
      "        -0.3066, -0.3065, -0.3075, -0.3067, -0.3099, -0.3124, -0.2994, -0.2724,\n",
      "        -0.2757, -0.2804, -0.2862, -0.2984, -0.3102, -0.3201, -0.3185, -0.3167,\n",
      "        -0.3145, -0.3122, -0.3106, -0.3060, -0.3032, -0.2991, -0.2989, -0.2984,\n",
      "        -0.2978, -0.2972, -0.2976, -0.2950, -0.2750, -0.2615, -0.2615, -0.2616,\n",
      "        -0.2628, -0.2628, -0.2591, -0.2587], dtype=torch.float64)\n",
      "tensor([-0.1466, -0.1006, -0.0738, -0.0949, -0.1174, -0.1263, -0.1357, -0.1411,\n",
      "        -0.1408, -0.1473, -0.1691, -0.2920, -0.2984, -0.3051, -0.3207, -0.3254,\n",
      "        -0.3269, -0.3276, -0.3256, -0.3177, -0.3120, -0.3077, -0.3066, -0.3065,\n",
      "        -0.3075, -0.3067, -0.3099, -0.3124, -0.2994, -0.2724, -0.2757, -0.2804,\n",
      "        -0.2862, -0.2984, -0.3102, -0.3201, -0.3185, -0.3167, -0.3145, -0.3122,\n",
      "        -0.3106, -0.3060, -0.3032, -0.2991, -0.2989, -0.2984, -0.2978, -0.2972,\n",
      "        -0.2976, -0.2950, -0.2750, -0.2615, -0.2615, -0.2616, -0.2628, -0.2628,\n",
      "        -0.2591, -0.2587, -0.2615, -0.2612], dtype=torch.float64)\n",
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "sdc, sda = circshift_dataset.__getitem__(2 * circshift_dataset.df_size + 1)\n",
    "dc, da = train_dataset.__getitem__(1)\n",
    "print(sda)\n",
    "print(da)\n",
    "print(len(sda))\n",
    "print(len(da))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2v_cqt_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
