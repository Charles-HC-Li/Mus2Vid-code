{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wreuzP62Wc11"
      },
      "source": [
        "# Music Genre Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsm0S0H5WiGN",
        "outputId": "b98d9b52-b483-4ce0-b5fa-1395e9fc880b"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZx1BNiqWk3N",
        "outputId": "10853909-750f-47b8-c339-3376baeb817e"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWLlSBsi8uBw"
      },
      "outputs": [],
      "source": [
        "# Credit: Code adapted and used from Sander Shi's Colab"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksk8OirqWc14"
      },
      "source": [
        "## Download and Parse Genre Labels\n",
        "* Go to the website http://www.tagtraum.com/msd_genre_datasets.html.\n",
        "* Look for the section labeled \"CD1\" and download the associated zip file.\n",
        "* Once the download is complete, unzip the file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEyTZ3teXmN8",
        "outputId": "0eda93ba-6c97-460e-e010-4325c1b70407"
      },
      "outputs": [],
      "source": [
        "# Unzips the \"CD1\" zip file\n",
        "!unzip msd_tagtraum_cd1.cls.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI4-EH5IWc15",
        "outputId": "dd21f9ea-a897-4695-9b97-4aed650d3109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Genre             TrackID\n",
            "0  Pop_Rock  TRAAAAK128F9318786\n",
            "1       Rap  TRAAAAW128F429D538\n",
            "2  Pop_Rock  TRAAABD128F429CF47\n",
            "3      Jazz  TRAAAED128E0783FAB\n",
            "4  Pop_Rock  TRAAAEF128F4273421\n",
            "\n",
            "['Folk', 'Pop_Rock', 'International', 'Electronic', 'Jazz', 'Country', 'Latin', 'New Age', 'RnB', 'Reggae', 'Vocal', 'Blues', 'Rap']\n",
            "\n",
            "{'Folk': 0, 'Pop_Rock': 1, 'International': 2, 'Electronic': 3, 'Jazz': 4, 'Country': 5, 'Latin': 6, 'New Age': 7, 'RnB': 8, 'Reggae': 9, 'Vocal': 10, 'Blues': 11, 'Rap': 12}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_genres(path):\n",
        "    \"\"\"\n",
        "    Stores the genre labels into a pandas data frame.\n",
        "    \n",
        "    Parameters:\n",
        "        path (str): The path to the genre label file.\n",
        "        \n",
        "    Returns:\n",
        "        pandas.DataFrame: A data frame containing the genres and MIDI IDs.\n",
        "    \"\"\"\n",
        "    ids = []\n",
        "    genres = []\n",
        "    \n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            # Skip lines starting with '#'\n",
        "            if not line.startswith('#'):\n",
        "                # Splits the line by the tab character ('\\t') and unpacks the resulting values \n",
        "                # into variables x and y. The strip() function removes leading and trailing whitespace from the line.\n",
        "                x, y, *_ = line.strip().split(\"\\t\")\n",
        "                # Appends the value of x (track ID) to the ids list.\n",
        "                ids.append(x)\n",
        "                # Appends the value of y (genre) to the genres list.\n",
        "                genres.append(y)\n",
        "    \n",
        "    # Constructs a data frame with two columns, \"Genre\" and \"TrackID\", using a dictionary. \n",
        "    # The \"Genre\" column contains the genres stored in the genres list, and the \"TrackID\" column \n",
        "    # contains the track IDs stored in the ids list.\n",
        "    genre_df = pd.DataFrame(data={\"Genre\": genres, \"TrackID\": ids})\n",
        "    return genre_df\n",
        "\n",
        "# genre_path: path of the unzipped \"CD1\" file\n",
        "genre_path = \"msd_tagtraum_cd1.cls\"\n",
        "# creates the genres data frame\n",
        "genre_df = get_genres(genre_path)\n",
        "\n",
        "# Get unique genre labels\n",
        "label_list = list(set(genre_df.Genre))\n",
        "\n",
        "# Create a dictionary mapping genre labels to their index\n",
        "label_dict = {lbl: label_list.index(lbl) for lbl in label_list}\n",
        "\n",
        "print(genre_df.head(), end=\"\\n\\n\")  # Display the first few rows of the genre data frame\n",
        "print(label_list, end=\"\\n\\n\")  # Display the unique genre labels\n",
        "print(label_dict, end=\"\\n\\n\")  # Display the genre dictionary mapping labels to indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SiYwTbgP59R",
        "outputId": "f39622b5-e65f-4c29-f170-41d12bd52445"
      },
      "outputs": [],
      "source": [
        "#cd /content/drive/MyDrive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeXBAkEWc15"
      },
      "source": [
        "## Download, Parse and Match Midi Files\n",
        "* Visit the website http://colinraffel.com/projects/lmd/.\n",
        "* Find the section titled \"LMD-matched\" and click on the provided link. This will initiate the download of a MIDI dataset where each file is matched to an entry in the million song dataset.\n",
        "* Once the download is complete, untar the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5x_vt4YX78",
        "outputId": "cc138f52-b57d-4779-f026-5a4260e9496c"
      },
      "outputs": [],
      "source": [
        "# Untars the downloaded file\n",
        "!tar -xvf lmd_matched.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-0CxSkKWc16",
        "outputId": "93325826-9bee-45cc-e388-82989116c127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                Path     Genre\n",
            "0  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B\\1d9d16a9d...  Pop_Rock\n",
            "1  lmd_matched\\A\\A\\D\\TRAADKW128E079503A\\3797e9b9a...  Pop_Rock\n",
            "2  lmd_matched\\A\\A\\F\\TRAAFMT128F429DB58\\0a4f2051b...  Pop_Rock\n",
            "3  lmd_matched\\A\\A\\G\\TRAAGMC128F4292D0F\\0644195d1...   Country\n",
            "4  lmd_matched\\A\\A\\L\\TRAALAH128E078234A\\8cfecf566...  Pop_Rock\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "def get_matched_midi(midi_folder, genre_df):\n",
        "    \"\"\"\n",
        "    Loads the MIDI file paths from the given folder and creates a pandas DataFrame.\n",
        "    Matches each MIDI file with a genre based on the genre_df generated by get_genres.\n",
        "\n",
        "    Parameters:\n",
        "        midi_folder (str): The path to the MIDI files folder.\n",
        "        genre_df (pandas.DataFrame): The genre label DataFrame generated by get_genres.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame containing the track ID and the path to the corresponding MIDI file.\n",
        "    \"\"\"\n",
        "    # Get all MIDI files\n",
        "    track_ids = []\n",
        "    file_paths = []\n",
        "\n",
        "    for dir_name, subdir_list, file_list in os.walk(midi_folder):\n",
        "        # Checks if the length of the directory name is equal to 36. \n",
        "        if len(dir_name) == 36:\n",
        "            # Extracts the track ID from the directory name by slicing the string from index 18 to the end\n",
        "            track_id = dir_name[18:]\n",
        "            # Constructs the file path by joining the directory name and the first file in the file_list\n",
        "            # ***(assumes that each directory contains only one MIDI file)*** \n",
        "            # ATTENTION: some directories actually contain more than one MIDI file for that genre\n",
        "            # file_list[0] is done for Simplification sake\n",
        "            file_path = os.path.join(dir_name, file_list[0])\n",
        "            track_ids.append(track_id)\n",
        "            file_paths.append(file_path)\n",
        "\n",
        "    # Constructs a DataFrame with two columns, \"TrackID\" and \"Path\", using a dictionary. \n",
        "    # The \"TrackID\" column contains the track IDs stored in the track_ids list, and \n",
        "    # The \"Path\" column contains the file paths stored in the file_paths list\n",
        "    all_midi_df = pd.DataFrame({\"TrackID\": track_ids, \"Path\": file_paths})\n",
        "\n",
        "    # Inner join the frames with the genre DataFrame\n",
        "    df = pd.merge(all_midi_df, genre_df, on='TrackID', how='inner')\n",
        "    \n",
        "    # Drop the redundant TrackID column\n",
        "    df = df.drop([\"TrackID\"], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# midi_path: path to lmd_matched folder created from running previous tar command\n",
        "midi_path = \"lmd_matched\"\n",
        "# matched_midi_df: data frame with matched genres to file paths\n",
        "matched_midi_df = get_matched_midi(midi_path, genre_df)\n",
        "\n",
        "# Optionally save the matched_midi_df DataFrame as a pickle file\n",
        "with open(\"matched_midi.pkl\", \"wb\") as f:\n",
        "    pickle.dump(matched_midi_df, f)\n",
        "\n",
        "# Print the first few rows\n",
        "print(matched_midi_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OASzJAAaPxb4",
        "outputId": "dbdb510c-4431-41bf-e5dc-683c72a145c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rEgO2gY9poS",
        "outputId": "e19acb69-5bfe-4379-ac2d-b15f61da3bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                Path     Genre\n",
            "0  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B\\1d9d16a9d...  Pop_Rock\n",
            "1  lmd_matched\\A\\A\\D\\TRAADKW128E079503A\\3797e9b9a...  Pop_Rock\n",
            "2  lmd_matched\\A\\A\\F\\TRAAFMT128F429DB58\\0a4f2051b...  Pop_Rock\n",
            "3  lmd_matched\\A\\A\\G\\TRAAGMC128F4292D0F\\0644195d1...   Country\n",
            "4  lmd_matched\\A\\A\\L\\TRAALAH128E078234A\\8cfecf566...  Pop_Rock\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# If saved, load matched_midi_df from the saved pickle file\n",
        "with open('matched_midi.pkl', 'rb') as f:\n",
        "    matched_midi_df = pickle.load(f)\n",
        "\n",
        "print(matched_midi_df.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a6F3c1s0Wc16"
      },
      "source": [
        "## Extract Midi Files Features\n",
        "\n",
        "* Ensure you have the necessary libraries installed, such as pretty_midi, numpy, librosa, fluidsynth, and pickle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8pSVM3XRbn4",
        "outputId": "01db45ed-6c33-4037-bcc0-c5fe3dc4e313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyfluidsynth in c:\\users\\jkamp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\jkamp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyfluidsynth) (1.24.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: C:\\Users\\jkamp\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Library needed for feature extraction\n",
        "!pip install pyfluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pqLVfz5oWc16",
        "outputId": "aa64b17b-ffa6-4d3d-a96e-5a18536f7068",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Couldn't find the FluidSynth library.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# import librosa\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfluidsynth\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\fluidsynth.py:44\u001b[0m\n\u001b[0;32m     37\u001b[0m lib \u001b[39m=\u001b[39m find_library(\u001b[39m'\u001b[39m\u001b[39mfluidsynth\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \\\n\u001b[0;32m     38\u001b[0m     find_library(\u001b[39m'\u001b[39m\u001b[39mlibfluidsynth\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \\\n\u001b[0;32m     39\u001b[0m     find_library(\u001b[39m'\u001b[39m\u001b[39mlibfluidsynth-3\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \\\n\u001b[0;32m     40\u001b[0m     find_library(\u001b[39m'\u001b[39m\u001b[39mlibfluidsynth-2\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \\\n\u001b[0;32m     41\u001b[0m     find_library(\u001b[39m'\u001b[39m\u001b[39mlibfluidsynth-1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m lib \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find the FluidSynth library.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[39m# Dynamically link the FluidSynth library\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# Architecture (32-/64-bit) must match your Python version\u001b[39;00m\n\u001b[0;32m     48\u001b[0m _fl \u001b[39m=\u001b[39m CDLL(lib)\n",
            "\u001b[1;31mImportError\u001b[0m: Couldn't find the FluidSynth library."
          ]
        }
      ],
      "source": [
        "# import librosa\n",
        "# import fluidsynth\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import warnings\n",
        "from sklearn.utils import resample\n",
        "  \n",
        "\n",
        "def normalize_features(features):\n",
        "    \"\"\"\n",
        "    Normalizes the features to the range [-1, 1].\n",
        "\n",
        "    Parameters:\n",
        "        features (list of float): The array of features.\n",
        "\n",
        "    Returns:\n",
        "        list of float: Normalized features.\n",
        "    \"\"\"\n",
        "    # Normalize each feature based on its specific range\n",
        "    tempo = (features[0] - 150) / 300\n",
        "    num_sig_changes = (features[1] - 2) / 10\n",
        "    resolution = (features[2] - 260) / 400\n",
        "    time_sig_1 = (features[3] - 3) / 8\n",
        "    time_sig_2 = (features[4] - 3) / 8\n",
        "    melody_complexity = (features[5] - 0) / 10\n",
        "    melody_range = (features[6] - 0) / 80\n",
        "\n",
        "    # Normalize pitch class histogram\n",
        "    pitch_class_hist = [((f - 0) / 100) for f in features[7:-1]]\n",
        "\n",
        "    # Return the normalized feature vector\n",
        "    return [tempo, resolution, time_sig_1, time_sig_2, melody_complexity, melody_range] + pitch_class_hist\n",
        "\n",
        "\n",
        "\n",
        "def get_features(path):\n",
        "    \"\"\"\n",
        "    Extracts specific features from a MIDI file given its path using the pretty_midi library.\n",
        "    Handle any potential errors with MIDI files appropriately.\n",
        "\n",
        "    Parameters:\n",
        "        path (str): The path to the MIDI file.\n",
        "\n",
        "    Returns:\n",
        "        list of float: The extracted features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Checking for MIDI files\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"error\")\n",
        "\n",
        "            # Creates a PrettyMIDI object by loading the MIDI file specified by the given path.\n",
        "            file = pretty_midi.PrettyMIDI(path)\n",
        "            \n",
        "            # tempo: the estimated tempo of the audio file\n",
        "            tempo = file.estimate_tempo()\n",
        "\n",
        "            # num_sig_changes: the number of time signature changes in the audio file\n",
        "            num_sig_changes = len(file.time_signature_changes)\n",
        "\n",
        "            # resolution: the time resolution of the audio file (in ticks per beat)\n",
        "            resolution = file.resolution\n",
        "\n",
        "\n",
        "            # Extract time signature information\n",
        "            ts_changes = file.time_signature_changes\n",
        "            ts_1, ts_2 = 4, 4\n",
        "            if len(ts_changes) > 0:\n",
        "                ts_1 = ts_changes[0].numerator\n",
        "                ts_2 = ts_changes[0].denominator\n",
        "            \n",
        "            # Extract melody-related features\n",
        "            # melody: a pitch class histogram of the audio file\n",
        "            melody = file.get_pitch_class_histogram()\n",
        "            # melody_complexity: the number of unique pitch classes in the melody\n",
        "            melody_complexity = np.sum(melody > 0)\n",
        "            # melody_range: the range of pitch classes in the melody\n",
        "            melody_range = np.max(melody) - np.min(melody)\n",
        "            # OPTIONAL feature melody_contour: the temporal evolution of pitch content in the audio file\n",
        "            # melody_contour = librosa.feature.tempogram(y=file.fluidsynth(fs=16000), sr=16000, hop_length=512)\n",
        "            # melody_contour = np.mean(melody_contour, axis=0)\n",
        "            # chroma: a chroma representation of the audio file\n",
        "            chroma = file.get_chroma()\n",
        "            # pitch_class_hist: the sum of the chroma matrix along the pitch axis\n",
        "            pitch_class_hist = np.sum(chroma, axis=1)\n",
        "\n",
        "            return normalize_features([tempo, num_sig_changes, resolution, ts_1,\n",
        "                            ts_2, melody_complexity, melody_range] + list(pitch_class_hist)) # + list(melody_contour))\n",
        "            \n",
        "    # Discard MIDI file if there is an error\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "            \n",
        "\n",
        "def extract_midi_features(path_df, oversample=False, undersample=False):\n",
        "    \"\"\"\n",
        "    Extracts features and labels from MIDI files listed in the path DataFrame and concatenates the\n",
        "    features with their labels into a matrix.\n",
        "\n",
        "    Since the dataset is inherently unbalanced in terms of genre distribution, oversampling and \n",
        "    undersampling can be used to achieve a more balanced representation of features for each genre.\n",
        "\n",
        "    Parameters:\n",
        "        path_df (pandas.DataFrame): A DataFrame with paths to MIDI files and their matched genre.\n",
        "        oversample (bool): Whether or not to perform oversampling on the data. Defaults to False.\n",
        "        undersample (bool): Whether or not to perform undersampling on the data. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A matrix of features along with labels.\n",
        "    \"\"\"\n",
        "    all_features = []  # List to store all extracted features\n",
        "    max_count = 0  # Variable to track the maximum count of MIDI files in a genre\n",
        "\n",
        "    # Iterate through each genre in label_dict\n",
        "    for genre in label_dict.keys(): #  Genre is the string from label_dict\n",
        "        genre_df = path_df.loc[path_df['Genre'] == genre]  # DataFrame containing MIDI files of the current genre\n",
        "        genre_count = len(genre_df)  # Count of MIDI files in the current genre\n",
        "        if genre_count > max_count:\n",
        "            max_count = genre_count  # Update the maximum count if the current genre has more MIDI files\n",
        "\n",
        "        features_list = []  # List to store features of MIDI files in the current genre\n",
        "        for index, row in genre_df.iterrows():\n",
        "            # Extract features from MIDI file\n",
        "            features = get_features(row.Path)\n",
        "            # Map genre label to a number\n",
        "            genre = label_dict[row.Genre]\n",
        "            if features is not None:\n",
        "                # Append the genre label to the feature vector\n",
        "                # (i.e., it concatenates the features with the labels into a matrix)\n",
        "                features.append(genre)\n",
        "                features_list.append(features)  # Append the feature vector to the list\n",
        "\n",
        "        if oversample:\n",
        "            # Resample the features to match the maximum count (oversampling)\n",
        "            features_list = resample(features_list, replace=True, n_samples=max_count, random_state=42)\n",
        "        elif undersample:\n",
        "            # Resample the features to match the maximum count (undersampling)\n",
        "            features_list = resample(features_list, replace=False, n_samples=max_count, random_state=42)\n",
        "\n",
        "        all_features += features_list  # Append the features of the current genre to the overall list\n",
        "\n",
        "    # Return the numpy array of all extracted features along with corresponding genres\n",
        "    return np.array(all_features)\n",
        "\n",
        "\n",
        "# Call the extract_midi_features function with the appropriate path DataFrame to extract the MIDI \n",
        "# file features and obtain the feature-label matrix\n",
        "labeled_features = extract_midi_features(matched_midi_df)\n",
        "# Print the labeled features\n",
        "print(labeled_features)\n",
        "\n",
        "# Optionally store the feature-label matrix as a pickle file for further use\n",
        "with open('labeled_features.pkl', 'wb') as f:\n",
        "    pickle.dump(labeled_features, f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4FRw4KCbWc17"
      },
      "source": [
        "## Partition Dataset into Training, Validation, and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ThBgMAJ1Wc17",
        "outputId": "04df37d3-562f-445f-b7e8-af9181f2fd26",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 2.33436608e-01 -5.00000000e-02  1.25000000e-01  1.25000000e-01\n",
            "   1.10000000e+00  2.50545653e-03  3.24309925e+04  3.02250000e+01\n",
            "   5.61119725e+04  1.09800000e+02  3.70535700e+04  3.39100000e+03\n",
            "   2.90382000e+04  6.45764000e+04  2.33650000e+03  3.26045600e+04\n",
            "   4.68375000e+01]\n",
            " [ 3.95454709e-01  5.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.20000000e+00  1.78347608e-03  1.48019000e+04  1.98571500e+04\n",
            "   5.61610000e+03  1.32613800e+04  3.11939400e+04  1.55619200e+04\n",
            "   1.53120600e+04  8.21883000e+03  2.04780000e+04  2.36144100e+04\n",
            "   4.77265000e+03]\n",
            " [ 2.96971127e-01  5.50000000e-01 -1.25000000e-01  1.25000000e-01\n",
            "   1.10000000e+00  2.03850143e-03  1.43411000e+04  7.25648000e+03\n",
            "   1.03569900e+04  1.61912900e+04  0.00000000e+00  1.12157500e+04\n",
            "   5.93757000e+03  1.35004500e+04  4.33746000e+03  7.60182000e+03\n",
            "   2.24264700e+04]\n",
            " [ 1.18608659e-01 -3.50000000e-01  6.25000000e-01  6.25000000e-01\n",
            "   1.20000000e+00  1.58796142e-03  9.22426873e+03  2.24757553e+04\n",
            "   8.62437045e+03  3.62284988e+04  3.01913223e+04  1.41965566e+04\n",
            "   2.89945834e+04  1.38234115e+04  3.61378448e+04  1.54964575e+04\n",
            "   2.65020163e+04]\n",
            " [ 8.66668231e-02  3.10000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.20000000e+00  1.97357418e-03  3.06501800e+04  3.36423000e+03\n",
            "   9.28497000e+03  1.52742900e+04  1.21386600e+04  1.65963600e+04\n",
            "   8.22198000e+03  7.47522000e+03  9.09320000e+03  1.68173400e+04\n",
            "   9.71550000e+03]\n",
            " [ 2.36097194e-01  5.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.20000000e+00  4.10893779e-03  1.39703625e+03  6.46214781e+03\n",
            "   1.44981813e+03  4.25543312e+03  4.22493847e+04  1.55834969e+03\n",
            "   8.63195000e+03  2.60405000e+03  1.12105338e+04  1.39325416e+04\n",
            "   2.22336281e+03]\n",
            " [ 6.03084483e-02  3.10000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.00000000e+00  3.13442482e-03  2.55925182e+04  2.01510912e+03\n",
            "   4.66879461e+04  1.94281711e+03  1.97608378e+04  0.00000000e+00\n",
            "   2.05606217e+04  3.80721383e+04  0.00000000e+00  1.87959628e+04\n",
            "   6.16635620e+01]\n",
            " [ 1.22329554e-01  3.10000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.00000000e+00  2.37546125e-03  4.06541085e+04  6.22087419e+02\n",
            "   3.97685342e+04  5.04803242e+02  3.42960767e+04  5.27590000e+03\n",
            "   9.42948000e+03  4.17740508e+04  1.74594442e+03  4.93129103e+04\n",
            "   6.95182593e+01]\n",
            " [ 2.87174307e-01 -3.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.10000000e+00  2.80069819e-03  1.99049263e+04  8.39595859e+04\n",
            "   1.90312500e+00  5.49480912e+04  2.96426250e+03  3.57455825e+04\n",
            "   5.98057337e+04  1.13518000e+03  8.48699881e+04  1.01875188e+03\n",
            "   3.73452400e+04]\n",
            " [ 2.69999782e-01  5.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.20000000e+00  2.88917637e-03  4.69202563e+03  1.05891150e+04\n",
            "   3.72865053e+04  1.81385781e+03  1.78164631e+04  1.98987500e+01\n",
            "   1.97814941e+04  1.81647272e+04  2.12712187e+02  2.81978956e+04\n",
            "   1.41130937e+02]]\n",
            "[ 1 12 12 12 12  3  3  8 12 12]\n",
            "[[0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Shuffle the features\n",
        "labeled_features = np.random.permutation(labeled_features)\n",
        "\n",
        "# Partition the Dataset into 3 Sets: Training, Validation, and Test\n",
        "num = len(labeled_features)\n",
        "# Calculate the number of samples for training data (60% of the dataset)\n",
        "num_training = int(num * 0.6)\n",
        "# Calculate the number of samples for validation data (20% of the dataset)\n",
        "num_validation = int(num * 0.8)\n",
        "\n",
        "# Extract the training data (60% of the labeled features)\n",
        "training_data = labeled_features[:num_training]\n",
        "# Extract the validation data (20% of the labeled features)\n",
        "validation_data = labeled_features[num_training:num_validation]\n",
        "# Extract the test data (remaining 20% of the labeled features)\n",
        "test_data = labeled_features[num_validation:]\n",
        "\n",
        "\n",
        "# Separate the features from the labels\n",
        "num_cols = training_data.shape[1] - 1\n",
        "# Extract features from the training data\n",
        "training_features = training_data[:, :num_cols]\n",
        "# Extract features from the validation data\n",
        "validation_features = validation_data[:, :num_cols]\n",
        "# Extract features from the test data\n",
        "test_features = test_data[:, :num_cols]\n",
        "\n",
        "# Format the features for this multi-class classification problem\n",
        "num_classes = len(label_list)\n",
        "# Extract labels from the training data and convert them to integers\n",
        "training_labels = training_data[:, num_cols].astype(int)\n",
        "# Extract labels from the validation data and convert them to integers\n",
        "validation_labels = validation_data[:, num_cols].astype(int)\n",
        "# Extract labels from the test data and convert them to integers\n",
        "test_labels = test_data[:, num_cols].astype(int)\n",
        "\n",
        "print(test_features[:10])  # Print the first 10 rows of test features\n",
        "print(test_labels[:10])  # Print the first 10 test labels\n",
        "print(to_categorical((test_labels)[:10]))  # Print the one-hot encoding of the first 10 test labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I6jbF2S2ZKWi",
        "outputId": "f8f680a5-2652-4618-bd54-314ff3396e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               4608      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 13)                845       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,605\n",
            "Trainable params: 46,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "75/75 - 7s - loss: 3432.3198 - accuracy: 0.4048 - val_loss: 276.1761 - val_accuracy: 0.7098 - 7s/epoch - 99ms/step\n",
            "Epoch 2/50\n",
            "75/75 - 0s - loss: 1072.8348 - accuracy: 0.4441 - val_loss: 128.5430 - val_accuracy: 0.7023 - 282ms/epoch - 4ms/step\n",
            "Epoch 3/50\n",
            "75/75 - 0s - loss: 570.0541 - accuracy: 0.4697 - val_loss: 70.8358 - val_accuracy: 0.7073 - 286ms/epoch - 4ms/step\n",
            "Epoch 4/50\n",
            "75/75 - 0s - loss: 333.0745 - accuracy: 0.4462 - val_loss: 21.7043 - val_accuracy: 0.6960 - 283ms/epoch - 4ms/step\n",
            "Epoch 5/50\n",
            "75/75 - 0s - loss: 204.1414 - accuracy: 0.4684 - val_loss: 3.8101 - val_accuracy: 0.7136 - 283ms/epoch - 4ms/step\n",
            "Epoch 6/50\n",
            "75/75 - 0s - loss: 104.9348 - accuracy: 0.5500 - val_loss: 3.4825 - val_accuracy: 0.7136 - 284ms/epoch - 4ms/step\n",
            "Epoch 7/50\n",
            "75/75 - 0s - loss: 46.2025 - accuracy: 0.6187 - val_loss: 2.8909 - val_accuracy: 0.7136 - 286ms/epoch - 4ms/step\n",
            "Epoch 8/50\n",
            "75/75 - 0s - loss: 28.5428 - accuracy: 0.6471 - val_loss: 2.6712 - val_accuracy: 0.7148 - 285ms/epoch - 4ms/step\n",
            "Epoch 9/50\n",
            "75/75 - 0s - loss: 17.8118 - accuracy: 0.6589 - val_loss: 2.3570 - val_accuracy: 0.7148 - 286ms/epoch - 4ms/step\n",
            "Epoch 10/50\n",
            "75/75 - 0s - loss: 14.6661 - accuracy: 0.6739 - val_loss: 2.2144 - val_accuracy: 0.7148 - 291ms/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "75/75 - 0s - loss: 13.0094 - accuracy: 0.6831 - val_loss: 2.1010 - val_accuracy: 0.7148 - 288ms/epoch - 4ms/step\n",
            "Epoch 12/50\n",
            "75/75 - 0s - loss: 10.3457 - accuracy: 0.6856 - val_loss: 1.9530 - val_accuracy: 0.7148 - 290ms/epoch - 4ms/step\n",
            "Epoch 13/50\n",
            "75/75 - 0s - loss: 7.4245 - accuracy: 0.6873 - val_loss: 1.8124 - val_accuracy: 0.7148 - 292ms/epoch - 4ms/step\n",
            "Epoch 14/50\n",
            "75/75 - 0s - loss: 6.9801 - accuracy: 0.6923 - val_loss: 1.7095 - val_accuracy: 0.7148 - 286ms/epoch - 4ms/step\n",
            "Epoch 15/50\n",
            "75/75 - 0s - loss: 4.5937 - accuracy: 0.6978 - val_loss: 1.6381 - val_accuracy: 0.7148 - 287ms/epoch - 4ms/step\n",
            "Epoch 16/50\n",
            "75/75 - 0s - loss: 3.3826 - accuracy: 0.6919 - val_loss: 1.5621 - val_accuracy: 0.7148 - 297ms/epoch - 4ms/step\n",
            "Epoch 17/50\n",
            "75/75 - 0s - loss: 4.8540 - accuracy: 0.6982 - val_loss: 1.5323 - val_accuracy: 0.7148 - 293ms/epoch - 4ms/step\n",
            "Epoch 18/50\n",
            "75/75 - 0s - loss: 3.5086 - accuracy: 0.6974 - val_loss: 1.4895 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "Epoch 19/50\n",
            "75/75 - 0s - loss: 4.5304 - accuracy: 0.6961 - val_loss: 1.4441 - val_accuracy: 0.7148 - 287ms/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "75/75 - 0s - loss: 2.7222 - accuracy: 0.6978 - val_loss: 1.4094 - val_accuracy: 0.7148 - 282ms/epoch - 4ms/step\n",
            "Epoch 21/50\n",
            "75/75 - 0s - loss: 2.7581 - accuracy: 0.7015 - val_loss: 1.3882 - val_accuracy: 0.7148 - 300ms/epoch - 4ms/step\n",
            "Epoch 22/50\n",
            "75/75 - 0s - loss: 4.1038 - accuracy: 0.7011 - val_loss: 1.2912 - val_accuracy: 0.7148 - 277ms/epoch - 4ms/step\n",
            "Epoch 23/50\n",
            "75/75 - 0s - loss: 3.7042 - accuracy: 0.6990 - val_loss: 1.2602 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "Epoch 24/50\n",
            "75/75 - 0s - loss: 2.5370 - accuracy: 0.6995 - val_loss: 1.2476 - val_accuracy: 0.7148 - 284ms/epoch - 4ms/step\n",
            "Epoch 25/50\n",
            "75/75 - 0s - loss: 2.3498 - accuracy: 0.7032 - val_loss: 1.2370 - val_accuracy: 0.7148 - 279ms/epoch - 4ms/step\n",
            "Epoch 26/50\n",
            "75/75 - 0s - loss: 2.0091 - accuracy: 0.7024 - val_loss: 1.2275 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "Epoch 27/50\n",
            "75/75 - 0s - loss: 1.6738 - accuracy: 0.7036 - val_loss: 1.2199 - val_accuracy: 0.7148 - 288ms/epoch - 4ms/step\n",
            "Epoch 28/50\n",
            "75/75 - 0s - loss: 3.7944 - accuracy: 0.7011 - val_loss: 1.2129 - val_accuracy: 0.7148 - 294ms/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "75/75 - 0s - loss: 2.6555 - accuracy: 0.7028 - val_loss: 1.2072 - val_accuracy: 0.7148 - 281ms/epoch - 4ms/step\n",
            "Epoch 30/50\n",
            "75/75 - 0s - loss: 2.1968 - accuracy: 0.7041 - val_loss: 1.2021 - val_accuracy: 0.7148 - 282ms/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "75/75 - 0s - loss: 1.9102 - accuracy: 0.7041 - val_loss: 1.1978 - val_accuracy: 0.7148 - 282ms/epoch - 4ms/step\n",
            "Epoch 32/50\n",
            "75/75 - 0s - loss: 1.5272 - accuracy: 0.7028 - val_loss: 1.1941 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "Epoch 33/50\n",
            "75/75 - 0s - loss: 1.5636 - accuracy: 0.7024 - val_loss: 1.1909 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "75/75 - 0s - loss: 1.3669 - accuracy: 0.7032 - val_loss: 1.1882 - val_accuracy: 0.7148 - 281ms/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "75/75 - 0s - loss: 1.9949 - accuracy: 0.7032 - val_loss: 1.1856 - val_accuracy: 0.7148 - 286ms/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "75/75 - 0s - loss: 2.1183 - accuracy: 0.7032 - val_loss: 1.1837 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "75/75 - 0s - loss: 1.3314 - accuracy: 0.7045 - val_loss: 1.1818 - val_accuracy: 0.7148 - 279ms/epoch - 4ms/step\n",
            "Epoch 38/50\n",
            "75/75 - 0s - loss: 3.4468 - accuracy: 0.7041 - val_loss: 1.1798 - val_accuracy: 0.7148 - 278ms/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "75/75 - 0s - loss: 1.5966 - accuracy: 0.7045 - val_loss: 1.1783 - val_accuracy: 0.7148 - 285ms/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "75/75 - 0s - loss: 1.4340 - accuracy: 0.7049 - val_loss: 1.1770 - val_accuracy: 0.7148 - 284ms/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "75/75 - 0s - loss: 1.8893 - accuracy: 0.7036 - val_loss: 1.1756 - val_accuracy: 0.7148 - 278ms/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "75/75 - 0s - loss: 1.5289 - accuracy: 0.7024 - val_loss: 1.1744 - val_accuracy: 0.7148 - 294ms/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "75/75 - 0s - loss: 2.0674 - accuracy: 0.7049 - val_loss: 1.1735 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "75/75 - 0s - loss: 1.7827 - accuracy: 0.7032 - val_loss: 1.1726 - val_accuracy: 0.7148 - 291ms/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "75/75 - 0s - loss: 1.5041 - accuracy: 0.7041 - val_loss: 1.1717 - val_accuracy: 0.7148 - 279ms/epoch - 4ms/step\n",
            "Epoch 46/50\n",
            "75/75 - 0s - loss: 1.3848 - accuracy: 0.7041 - val_loss: 1.1711 - val_accuracy: 0.7148 - 284ms/epoch - 4ms/step\n",
            "Epoch 47/50\n",
            "75/75 - 0s - loss: 1.5729 - accuracy: 0.7041 - val_loss: 1.1702 - val_accuracy: 0.7148 - 276ms/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "75/75 - 0s - loss: 1.2403 - accuracy: 0.7036 - val_loss: 1.1696 - val_accuracy: 0.7148 - 278ms/epoch - 4ms/step\n",
            "Epoch 49/50\n",
            "75/75 - 0s - loss: 2.2433 - accuracy: 0.7041 - val_loss: 1.1689 - val_accuracy: 0.7148 - 281ms/epoch - 4ms/step\n",
            "Epoch 50/50\n",
            "75/75 - 0s - loss: 1.3437 - accuracy: 0.7049 - val_loss: 1.1684 - val_accuracy: 0.7148 - 283ms/epoch - 4ms/step\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 1.1959 - accuracy: 0.7102\n",
            "Test Loss: 1.1959456205368042\n",
            "Test Accuracy: 0.7101631164550781\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder  \n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "    # First hidden layer with 256 units and ReLU activation\n",
        "    keras.layers.Dense(256, input_shape=(training_features.shape[1],), activation='relu'),\n",
        "    keras.layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    \n",
        "    # Second hidden layer with 128 units and ReLU activation\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    \n",
        "    # Third hidden layer with 64 units and ReLU activation\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    \n",
        "    # Output layer with num_classes units and softmax activation for multi-class classification\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "optimizer=\"adam\": The optimizer algorithm to use during training. \n",
        "Adam optimizer is chosen, which is a popular optimization algorithm known for its efficiency.\n",
        "\n",
        "loss='categorical_crossentropy': The loss function used to measure the discrepancy between the \n",
        "predicted output and the true output labels. Categorical cross-entropy is suitable for\n",
        "multi-class classification tasks.\n",
        "\n",
        "metrics=['accuracy']: The metric(s) to be evaluated during training and testing. \n",
        "Accuracy is a commonly used metric to assess the model's performance.\n",
        "\"\"\"\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Encode the training and validation labels using one-hot encoding\n",
        "train_labels_encoded = to_categorical(training_labels)\n",
        "val_labels_encoded = to_categorical(validation_labels)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "training_features, train_labels_encoded: Input features and corresponding labels for model training.\n",
        "\n",
        "validation_features, val_labels_encoded: Validation set used to monitor the model's performance \n",
        "                                         during training.\n",
        "\n",
        "batch_size=32: Number of samples per gradient update. Training data is divided into batches, \n",
        "               and the model's weights are updated after each batch.\n",
        "\n",
        "epochs=50: Number of times the model will iterate over the entire training dataset.\n",
        "\n",
        "callbacks: EarlyStopping to stop training if the validation loss does not improve for a certain \n",
        "           number of epochs, and ModelCheckpoint to save the best model based on validation loss.\n",
        "\"\"\"\n",
        "history = model.fit(training_features, train_labels_encoded, \n",
        "                    validation_data=(validation_features, val_labels_encoded),\n",
        "                    batch_size=32, epochs=50, verbose=2,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
        "                               keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)])\n",
        "\n",
        "# Save the entire model to an h5 file\n",
        "model.save(\"my_model.h5\")\n",
        "\n",
        "# Optionally save the entire model as a pickle file\n",
        "with open('my_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "\n",
        "# Optionally load the pickled model from file\n",
        "with open('my_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Use the loaded model for prediction\n",
        "preds = model.predict(test_features)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_features, to_categorical(test_labels))\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
