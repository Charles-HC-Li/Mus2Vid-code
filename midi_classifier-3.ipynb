{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wreuzP62Wc11"
      },
      "source": [
        "# Music Genre Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsm0S0H5WiGN",
        "outputId": "b98d9b52-b483-4ce0-b5fa-1395e9fc880b"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZx1BNiqWk3N",
        "outputId": "10853909-750f-47b8-c339-3376baeb817e"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWLlSBsi8uBw"
      },
      "outputs": [],
      "source": [
        "# Credit: Code adapted and used from Sander Shi's Colab"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ksk8OirqWc14"
      },
      "source": [
        "## Download and Parse Genre Labels\n",
        "* Go to the website http://www.tagtraum.com/msd_genre_datasets.html.\n",
        "* Look for the section labeled \"CD1\" and download the associated zip file.\n",
        "* Once the download is complete, unzip the file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEyTZ3teXmN8",
        "outputId": "0eda93ba-6c97-460e-e010-4325c1b70407"
      },
      "outputs": [],
      "source": [
        "# Unzips the \"CD1\" zip file\n",
        "!unzip msd_tagtraum_cd1.cls.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI4-EH5IWc15",
        "outputId": "dd21f9ea-a897-4695-9b97-4aed650d3109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Genre             TrackID\n",
            "0  Pop_Rock  TRAAAAK128F9318786\n",
            "1       Rap  TRAAAAW128F429D538\n",
            "2  Pop_Rock  TRAAABD128F429CF47\n",
            "3      Jazz  TRAAAED128E0783FAB\n",
            "4  Pop_Rock  TRAAAEF128F4273421\n",
            "\n",
            "['Folk', 'Country', 'Pop_Rock', 'International', 'Vocal', 'RnB', 'New Age', 'Blues', 'Latin', 'Jazz', 'Reggae', 'Rap', 'Electronic']\n",
            "\n",
            "{'Folk': 0, 'Country': 1, 'Pop_Rock': 2, 'International': 3, 'Vocal': 4, 'RnB': 5, 'New Age': 6, 'Blues': 7, 'Latin': 8, 'Jazz': 9, 'Reggae': 10, 'Rap': 11, 'Electronic': 12}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_genres(path):\n",
        "    \"\"\"\n",
        "    Stores the genre labels into a pandas data frame.\n",
        "    \n",
        "    Parameters:\n",
        "        path (str): The path to the genre label file.\n",
        "        \n",
        "    Returns:\n",
        "        pandas.DataFrame: A data frame containing the genres and MIDI IDs.\n",
        "    \"\"\"\n",
        "    ids = []\n",
        "    genres = []\n",
        "    \n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            # Skip lines starting with '#'\n",
        "            if not line.startswith('#'):\n",
        "                # Splits the line by the tab character ('\\t') and unpacks the resulting values \n",
        "                # into variables x and y. The strip() function removes leading and trailing whitespace from the line.\n",
        "                x, y, *_ = line.strip().split(\"\\t\")\n",
        "                # Appends the value of x (track ID) to the ids list.\n",
        "                ids.append(x)\n",
        "                # Appends the value of y (genre) to the genres list.\n",
        "                genres.append(y)\n",
        "    \n",
        "    # Constructs a data frame with two columns, \"Genre\" and \"TrackID\", using a dictionary. \n",
        "    # The \"Genre\" column contains the genres stored in the genres list, and the \"TrackID\" column \n",
        "    # contains the track IDs stored in the ids list.\n",
        "    genre_df = pd.DataFrame(data={\"Genre\": genres, \"TrackID\": ids})\n",
        "\n",
        "    return genre_df\n",
        "\n",
        "# genre_path: path of the unzipped \"CD1\" file\n",
        "genre_path = \"msd_tagtraum_cd1.cls\"\n",
        "# creates the genres data frame\n",
        "genre_df = get_genres(genre_path)\n",
        "\n",
        "# Get unique genre labels\n",
        "label_list = list(set(genre_df.Genre))\n",
        "\n",
        "# Create a dictionary mapping genre labels to their index\n",
        "label_dict = {lbl: label_list.index(lbl) for lbl in label_list}\n",
        "\n",
        "print(genre_df.head(), end=\"\\n\\n\")  # Display the first few rows of the genre data frame\n",
        "print(label_list, end=\"\\n\\n\")  # Display the unique genre labels\n",
        "print(label_dict, end=\"\\n\\n\")  # Display the genre dictionary mapping labels to indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SiYwTbgP59R",
        "outputId": "f39622b5-e65f-4c29-f170-41d12bd52445"
      },
      "outputs": [],
      "source": [
        "#cd /content/drive/MyDrive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeXBAkEWc15"
      },
      "source": [
        "## Download, Parse and Match Midi Files\n",
        "* Visit the website http://colinraffel.com/projects/lmd/.\n",
        "* Find the section titled \"LMD-matched\" and click on the provided link. This will initiate the download of a MIDI dataset where each file is matched to an entry in the million song dataset.\n",
        "* Once the download is complete, untar the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5x_vt4YX78",
        "outputId": "cc138f52-b57d-4779-f026-5a4260e9496c"
      },
      "outputs": [],
      "source": [
        "# Untars the downloaded file\n",
        "!tar -xvf lmd_matched.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-0CxSkKWc16",
        "outputId": "93325826-9bee-45cc-e388-82989116c127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31034\n",
            "                                                Path     Genre\n",
            "0  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B\\1d9d16a9d...  Pop_Rock\n",
            "1  lmd_matched\\A\\A\\D\\TRAADKW128E079503A\\3797e9b9a...  Pop_Rock\n",
            "2  lmd_matched\\A\\A\\F\\TRAAFMT128F429DB58\\0a4f2051b...  Pop_Rock\n",
            "3  lmd_matched\\A\\A\\G\\TRAAGMC128F4292D0F\\0644195d1...   Country\n",
            "4  lmd_matched\\A\\A\\L\\TRAALAH128E078234A\\8cfecf566...  Pop_Rock\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "def get_matched_midi(midi_folder, genre_df):\n",
        "    \"\"\"\n",
        "    Loads the MIDI file paths from the given folder and creates a pandas DataFrame.\n",
        "    Matches each MIDI file with a genre based on the genre_df generated by get_genres.\n",
        "\n",
        "    Parameters:\n",
        "        midi_folder (str): The path to the MIDI files folder.\n",
        "        genre_df (pandas.DataFrame): The genre label DataFrame generated by get_genres.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame containing the track ID and the path to the corresponding MIDI file.\n",
        "    \"\"\"\n",
        "    # Get all MIDI files\n",
        "    track_ids = []\n",
        "    file_paths = []\n",
        "\n",
        "    for dir_name, subdir_list, file_list in os.walk(midi_folder):\n",
        "        # Checks if the length of the directory name is equal to 36. \n",
        "        if len(dir_name) == 36:\n",
        "            # Extracts the track ID from the directory name by slicing the string from index 18 to the end\n",
        "            track_id = dir_name[18:]\n",
        "            # Constructs the file path by joining the directory name and the first file in the file_list\n",
        "            # ***(assumes that each directory contains only one MIDI file)*** \n",
        "            # ATTENTION: some directories actually contain more than one MIDI file for that genre\n",
        "            # file_list[0] is done for Simplification sake\n",
        "            file_path = os.path.join(dir_name, file_list[0])\n",
        "            track_ids.append(track_id)\n",
        "            file_paths.append(file_path)\n",
        "\n",
        "    # Constructs a DataFrame with two columns, \"TrackID\" and \"Path\", using a dictionary. \n",
        "    # The \"TrackID\" column contains the track IDs stored in the track_ids list, and \n",
        "    # The \"Path\" column contains the file paths stored in the file_paths list\n",
        "    all_midi_df = pd.DataFrame({\"TrackID\": track_ids, \"Path\": file_paths})\n",
        "\n",
        "    # Inner join the frames with the genre DataFrame\n",
        "    df = pd.merge(all_midi_df, genre_df, on='TrackID', how='inner')\n",
        "    \n",
        "    # Drop the redundant TrackID column\n",
        "    df = df.drop([\"TrackID\"], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# midi_path: path to lmd_matched folder created from running previous tar command\n",
        "midi_path = \"lmd_matched\"\n",
        "# matched_midi_df: data frame with matched genres to file paths\n",
        "matched_midi_df = get_matched_midi(midi_path, genre_df)\n",
        "\n",
        "# Optionally save the matched_midi_df DataFrame as a pickle file\n",
        "with open(\"matched_midi.pkl\", \"wb\") as f:\n",
        "    pickle.dump(matched_midi_df, f)\n",
        "\n",
        "# Print the first few rows\n",
        "print(matched_midi_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OASzJAAaPxb4",
        "outputId": "dbdb510c-4431-41bf-e5dc-683c72a145c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rEgO2gY9poS",
        "outputId": "e19acb69-5bfe-4379-ac2d-b15f61da3bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                Path     Genre\n",
            "0  lmd_matched\\A\\A\\A\\TRAAAGR128F425B14B\\1d9d16a9d...  Pop_Rock\n",
            "1  lmd_matched\\A\\A\\D\\TRAADKW128E079503A\\3797e9b9a...  Pop_Rock\n",
            "2  lmd_matched\\A\\A\\F\\TRAAFMT128F429DB58\\0a4f2051b...  Pop_Rock\n",
            "3  lmd_matched\\A\\A\\G\\TRAAGMC128F4292D0F\\0644195d1...   Country\n",
            "4  lmd_matched\\A\\A\\L\\TRAALAH128E078234A\\8cfecf566...  Pop_Rock\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# If saved, load matched_midi_df from the saved pickle file\n",
        "with open('matched_midi.pkl', 'rb') as f:\n",
        "    matched_midi_df = pickle.load(f)\n",
        "\n",
        "print(matched_midi_df.head())\n",
        "# print(len(matched_midi_df))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a6F3c1s0Wc16"
      },
      "source": [
        "## Extract Midi Files Features\n",
        "\n",
        "* Ensure you have the necessary libraries installed, such as pretty_midi, numpy, librosa, fluidsynth, and pickle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8pSVM3XRbn4",
        "outputId": "01db45ed-6c33-4037-bcc0-c5fe3dc4e313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyfluidsynth in c:\\users\\jkamp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\jkamp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyfluidsynth) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# Library needed for feature extraction\n",
        "!pip install pyfluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pqLVfz5oWc16",
        "outputId": "aa64b17b-ffa6-4d3d-a96e-5a18536f7068",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lmd_matched\\A\\F\\Q\\TRAFQFM128E078EC97\\3d5a78da77f009eb88641731e91d6982.mid\n",
            "lmd_matched\\A\\K\\Y\\TRAKYHY128F933BB51\\818034a239a474977975b5d18a7ae15a.mid\n",
            "lmd_matched\\A\\Z\\C\\TRAZCCG128F1463460\\986d9f7a327bf3487c98c55bcf23c920.mid\n",
            "lmd_matched\\B\\E\\R\\TRBERAT128F428036D\\21a3deefcd110324ac64c96f3ad39eb3.mid\n",
            "lmd_matched\\B\\K\\F\\TRBKFKL128E078ED76\\50eaa6135fdff0b9aac62318330500f4.mid\n",
            "lmd_matched\\C\\A\\H\\TRCAHUS128F14648B1\\b7ce9466c5cecbf1f19520cbe0e3c8cc.mid\n",
            "lmd_matched\\C\\G\\V\\TRCGVHG128F42A6C1F\\d2a37714c56480ba377bd4eea234ff98.mid\n",
            "lmd_matched\\C\\L\\O\\TRCLOST128E079221A\\7c6c1eac12c9bc2bda71d4f98b9ee13c.mid\n",
            "lmd_matched\\D\\R\\F\\TRDRFEV128F429E604\\d89d5403ee99245aa11283a8cec10e8c.mid\n",
            "lmd_matched\\D\\W\\M\\TRDWMEN128F935A08C\\02b3449d6e4c6e29571b2272e11ab1b8.mid\n",
            "lmd_matched\\F\\A\\E\\TRFAEIY128F42619B5\\aef10f61a1505fa8333cddd166396aa6.mid\n",
            "lmd_matched\\F\\U\\S\\TRFUSOG128E078EC6F\\28cc1b9acc9f23505d1b97f969d6df5e.mid\n",
            "lmd_matched\\F\\Y\\V\\TRFYVIE128F148C86E\\aab67d778d956bee5d7135bbb0bba121.mid\n",
            "lmd_matched\\G\\D\\X\\TRGDXSF128F428B57C\\40140e92ac87961dff491b962cd16317.mid\n",
            "lmd_matched\\G\\H\\Q\\TRGHQUR128E0783EEB\\ac4c4c7da2de1a739a6b462c3eea110e.mid\n",
            "lmd_matched\\G\\O\\C\\TRGOCCP128F92F3AE3\\12990033cb9629058248356824976899.mid\n",
            "lmd_matched\\G\\S\\S\\TRGSSCI128F933D9C1\\49a4d9293cd53d082a50c24a94084e97.mid\n",
            "lmd_matched\\G\\V\\I\\TRGVIDQ128F92C79D8\\def082823a768154a9b50adbbea3bcaa.mid\n",
            "lmd_matched\\G\\W\\I\\TRGWIPY12903D00F3E\\1fea22683b6fe65756da4388816b7785.mid\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# import librosa\n",
        "# import fluidsynth\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import warnings\n",
        "from sklearn.utils import resample\n",
        "  \n",
        "\n",
        "def normalize_features(features):\n",
        "    \"\"\"\n",
        "    Normalizes the features to the range [-1, 1].\n",
        "\n",
        "    Parameters:\n",
        "        features (list of float): The array of features.\n",
        "\n",
        "    Returns:\n",
        "        list of float: Normalized features.\n",
        "    \"\"\"\n",
        "    # Normalize each feature based on its specific range\n",
        "    tempo = (features[0] - 150) / 300\n",
        "    num_sig_changes = (features[1] - 2) / 10\n",
        "    resolution = (features[2] - 260) / 400\n",
        "    time_sig_1 = (features[3] - 3) / 8\n",
        "    time_sig_2 = (features[4] - 3) / 8\n",
        "    melody_complexity = (features[5] - 0) / 10\n",
        "    melody_range = (features[6] - 0) / 80\n",
        "\n",
        "    # Normalize pitch class histogram\n",
        "    pitch_class_hist = [((f - 0) / 100) for f in features[7:-1]]\n",
        "\n",
        "    # Return the normalized feature vector\n",
        "    return [tempo, resolution, time_sig_1, time_sig_2, melody_complexity, melody_range] + pitch_class_hist\n",
        "\n",
        "\n",
        "\n",
        "def get_features(path):\n",
        "    \"\"\"\n",
        "    Extracts specific features from a MIDI file given its path using the pretty_midi library.\n",
        "    Handle any potential errors with MIDI files appropriately.\n",
        "\n",
        "    Parameters:\n",
        "        path (str): The path to the MIDI file.\n",
        "\n",
        "    Returns:\n",
        "        list of float: The extracted features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Checking for MIDI files\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"error\")\n",
        "\n",
        "            # Creates a PrettyMIDI object by loading the MIDI file specified by the given path.\n",
        "            file = pretty_midi.PrettyMIDI(path)\n",
        "            \n",
        "            # tempo: the estimated tempo of the audio file\n",
        "            tempo = file.estimate_tempo()\n",
        "\n",
        "            # num_sig_changes: the number of time signature changes in the audio file\n",
        "            num_sig_changes = len(file.time_signature_changes)\n",
        "\n",
        "            # resolution: the time resolution of the audio file (in ticks per beat)\n",
        "            resolution = file.resolution\n",
        "\n",
        "\n",
        "            # Extract time signature information\n",
        "            ts_changes = file.time_signature_changes\n",
        "            ts_1, ts_2 = 4, 4\n",
        "            if len(ts_changes) > 0:\n",
        "                ts_1 = ts_changes[0].numerator\n",
        "                ts_2 = ts_changes[0].denominator\n",
        "            \n",
        "            # Extract melody-related features\n",
        "            # melody: a pitch class histogram of the audio file\n",
        "            melody = file.get_pitch_class_histogram()\n",
        "            # melody_complexity: the number of unique pitch classes in the melody\n",
        "            melody_complexity = np.sum(melody > 0)\n",
        "            # melody_range: the range of pitch classes in the melody\n",
        "            melody_range = np.max(melody) - np.min(melody)\n",
        "            # OPTIONAL feature melody_contour: the temporal evolution of pitch content in the audio file\n",
        "            # melody_contour = librosa.feature.tempogram(y=file.fluidsynth(fs=16000), sr=16000, hop_length=512)\n",
        "            # melody_contour = np.mean(melody_contour, axis=0)\n",
        "            # chroma: a chroma representation of the audio file\n",
        "            chroma = file.get_chroma()\n",
        "            # pitch_class_hist: the sum of the chroma matrix along the pitch axis\n",
        "            pitch_class_hist = np.sum(chroma, axis=1)\n",
        "\n",
        "            return normalize_features([tempo, num_sig_changes, resolution, ts_1,\n",
        "                            ts_2, melody_complexity, melody_range] + list(pitch_class_hist)) # + list(melody_contour))\n",
        "            \n",
        "    # Discard MIDI file if there is an error\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "            \n",
        "\n",
        "def extract_midi_features(path_df, oversample=True, undersample=False):\n",
        "    \"\"\"\n",
        "    Extracts features and labels from MIDI files listed in the path DataFrame and concatenates the\n",
        "    features with their labels into a matrix.\n",
        "\n",
        "    Since the dataset is inherently unbalanced in terms of genre distribution, oversampling and \n",
        "    undersampling can be used to achieve a more balanced representation of features for each genre.\n",
        "\n",
        "    Parameters:\n",
        "        path_df (pandas.DataFrame): A DataFrame with paths to MIDI files and their matched genre.\n",
        "        oversample (bool): Whether or not to perform oversampling on the data. Defaults to False.\n",
        "        undersample (bool): Whether or not to perform undersampling on the data. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A matrix of features along with labels.\n",
        "    \"\"\"\n",
        "    all_features = []  # List to store all extracted features\n",
        "    max_count = 0  # Variable to track the maximum count of MIDI files in a genre\n",
        "\n",
        "    # Iterate through each genre in label_dict\n",
        "    for genre in label_dict.keys(): #  Genre is the string from label_dict\n",
        "        genre_df = path_df.loc[path_df['Genre'] == genre]  # DataFrame containing MIDI files of the current genre\n",
        "        genre_count = len(genre_df)  # Count of MIDI files in the current genre\n",
        "        if genre_count > max_count:\n",
        "            max_count = genre_count  # Update the maximum count if the current genre has more MIDI files\n",
        "\n",
        "        features_list = []  # List to store features of MIDI files in the current genre\n",
        "        for index, row in genre_df.iterrows():\n",
        "            # Extract features from MIDI file\n",
        "            features = get_features(row.Path)\n",
        "            # Map genre label to a number\n",
        "            genre = label_dict[row.Genre]\n",
        "            if features is not None:\n",
        "                # Append the genre label to the feature vector\n",
        "                # (i.e., it concatenates the features with the labels into a matrix)\n",
        "                features.append(genre)\n",
        "                features_list.append(features)  # Append the feature vector to the list\n",
        "\n",
        "        if oversample:\n",
        "            # Resample the features to match the maximum count (oversampling)\n",
        "            features_list = resample(features_list, replace=True, n_samples=max_count, random_state=42)\n",
        "        elif undersample:\n",
        "            # Resample the features to match the maximum count (undersampling)\n",
        "            features_list = resample(features_list, replace=False, n_samples=max_count, random_state=42)\n",
        "\n",
        "        all_features += features_list  # Append the features of the current genre to the overall list\n",
        "\n",
        "    # Return the numpy array of all extracted features along with corresponding genres\n",
        "    return np.array(all_features)\n",
        "\n",
        "\n",
        "# Call the extract_midi_features function with the appropriate path DataFrame to extract the MIDI \n",
        "# file features and obtain the feature-label matrix\n",
        "labeled_features = extract_midi_features(matched_midi_df)\n",
        "# Print the labeled features\n",
        "print(labeled_features)\n",
        "\n",
        "# Optionally store the feature-label matrix as a pickle file for further use\n",
        "with open('labeled_features_over.pkl', 'wb') as f:\n",
        "    pickle.dump(labeled_features, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3978\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# If saved, load matched_midi_df from the saved pickle file\n",
        "with open('labeled_features.pkl', 'rb') as f:\n",
        "    labeled_features = pickle.load(f)\n",
        "\n",
        "print(len(labeled_features))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4FRw4KCbWc17"
      },
      "source": [
        "## Partition Dataset into Training, Validation, and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ThBgMAJ1Wc17",
        "outputId": "04df37d3-562f-445f-b7e8-af9181f2fd26",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 2.99979920e-01 -1.70000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.20000000e+00  4.97813224e-03  4.29900183e+04  6.55117954e+03\n",
            "   4.05010314e+04  5.52107382e+03  5.28387227e+03  1.89953786e+04\n",
            "   7.52076145e+02  1.00014923e+05  8.26752053e+03  4.29505859e+03\n",
            "   2.65193130e+04]\n",
            " [ 9.12467635e-02  5.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   9.00000000e-01  4.59501558e-03  1.04192148e+02  1.14963395e+04\n",
            "   3.99599926e+04  3.01748145e+01  2.79487596e+04  7.84877515e+01\n",
            "   1.37692734e+04  2.29059500e+04  1.25965747e+01  8.34516747e+04\n",
            "   4.28345508e+01]\n",
            " [ 1.97863042e-02 -5.00000000e-02  1.25000000e-01  1.25000000e-01\n",
            "   7.00000000e-01  3.30779944e-03  1.77018900e+04  0.00000000e+00\n",
            "   1.56785000e+04  1.03907031e+01  1.42147217e+03  4.25281971e+04\n",
            "   0.00000000e+00  2.47300600e+04  0.00000000e+00  7.12184000e+03\n",
            "   3.42498100e+04]\n",
            " [ 4.66669036e-02 -1.70000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.00000000e+00  3.92887117e-03  1.84596000e+03  8.45330000e+02\n",
            "   3.83261600e+04  0.00000000e+00  9.22286000e+03  9.00130000e+03\n",
            "   3.96962000e+03  1.40077500e+04  0.00000000e+00  1.85133400e+04\n",
            "   1.32574800e+04]\n",
            " [ 4.41753065e-01  5.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   6.00000000e-01  3.18396226e-03  0.00000000e+00  0.00000000e+00\n",
            "   2.14570000e+03  2.10740000e+03  0.00000000e+00  1.16480000e+03\n",
            "   0.00000000e+00  2.93185000e+03  0.00000000e+00  3.06400000e+02\n",
            "   2.49525000e+03]\n",
            " [ 1.86793189e-01  5.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   7.00000000e-01  2.47013652e-03  9.50255656e+03  5.95312500e-01\n",
            "   1.68564388e+04  5.70706250e+01  1.16748206e+04  4.96093750e+00\n",
            "   1.54761766e+04  1.89074425e+04  0.00000000e+00  1.22658894e+04\n",
            "   1.11650000e+01]\n",
            " [ 2.99719853e-01  3.10000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.20000000e+00  3.31632653e-03  1.45080000e+02  1.68683600e+04\n",
            "   3.51366300e+04  1.39820000e+02  1.52521800e+04  9.08007500e+02\n",
            "   2.26051991e+04  1.82167845e+04  8.59271455e+02  4.37645549e+04\n",
            "   1.79639372e+03]\n",
            " [ 2.89520636e-01 -1.70000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   9.00000000e-01  5.45088358e-03  9.57500906e+03  1.11964063e+01\n",
            "   1.13992834e+04  5.52698437e+01  3.86409013e+04  2.35769102e+04\n",
            "   2.44371953e+02  3.36871173e+04  1.68249219e+01  1.60901405e+04\n",
            "   4.51079844e+02]\n",
            " [ 1.96296296e-01 -4.10000000e-01 -2.50000000e-01  1.25000000e-01\n",
            "   1.00000000e+00  2.59779951e-03  2.60117400e+04  0.00000000e+00\n",
            "   1.64331800e+04  2.23742000e+03  1.84345800e+04  9.99376000e+03\n",
            "   0.00000000e+00  2.51285000e+04  9.60600000e+02  9.96504000e+03\n",
            "   1.74102000e+03]\n",
            " [ 1.00556243e-01 -3.50000000e-01  1.25000000e-01  1.25000000e-01\n",
            "   1.20000000e+00  2.14833244e-03  4.04748213e+04  9.21692898e+02\n",
            "   2.62649368e+04  3.94078338e+03  1.56941285e+04  2.89565944e+04\n",
            "   2.05825729e+03  4.31895321e+04  6.26322653e+03  2.14539587e+04\n",
            "   7.71388552e+03]]\n",
            "[1 1 1 1 1 1 1 8 1 1]\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Shuffle the features\n",
        "labeled_features = np.random.permutation(labeled_features)\n",
        "\n",
        "# Partition the Dataset into 3 Sets: Training, Validation, and Test\n",
        "num = len(labeled_features)\n",
        "# Calculate the number of samples for training data (60% of the dataset)\n",
        "num_training = int(num * 0.6)\n",
        "# Calculate the number of samples for validation data (20% of the dataset)\n",
        "num_validation = int(num * 0.8)\n",
        "\n",
        "# Extract the training data (60% of the labeled features)\n",
        "training_data = labeled_features[:num_training]\n",
        "# Extract the validation data (20% of the labeled features)\n",
        "validation_data = labeled_features[num_training:num_validation]\n",
        "# Extract the test data (remaining 20% of the labeled features)\n",
        "test_data = labeled_features[num_validation:]\n",
        "\n",
        "\n",
        "# Separate the features from the labels\n",
        "num_cols = training_data.shape[1] - 1\n",
        "# Extract features from the training data\n",
        "training_features = training_data[:, :num_cols]\n",
        "# Extract features from the validation data\n",
        "validation_features = validation_data[:, :num_cols]\n",
        "# Extract features from the test data\n",
        "test_features = test_data[:, :num_cols]\n",
        "\n",
        "# Format the features for this multi-class classification problem\n",
        "num_classes = len(label_list)\n",
        "# Extract labels from the training data and convert them to integers\n",
        "training_labels = training_data[:, num_cols].astype(int)\n",
        "# Extract labels from the validation data and convert them to integers\n",
        "validation_labels = validation_data[:, num_cols].astype(int)\n",
        "# Extract labels from the test data and convert them to integers\n",
        "test_labels = test_data[:, num_cols].astype(int)\n",
        "\n",
        "print(test_features[:10])  # Print the first 10 rows of test features\n",
        "print(test_labels[:10])  # Print the first 10 test labels\n",
        "print(to_categorical((test_labels)[:10]))  # Print the one-hot encoding of the first 10 test labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Folk', 'Country', 'Pop_Rock', 'International', 'Vocal', 'RnB', 'New Age', 'Blues', 'Latin', 'Jazz', 'Reggae', 'Rap', 'Electronic']\n",
            "3978 [25, 2813, 13, 287, 98, 319, 118, 48, 148, 27, 11, 10, 61]\n"
          ]
        }
      ],
      "source": [
        "# print(test_labels)\n",
        "num_labels = 0\n",
        "num_genres = [0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "for i in labeled_features[:, num_cols].astype(int):\n",
        "    num_labels += 1\n",
        "    num_genres[i] += 1\n",
        "\n",
        "print(label_list)\n",
        "print (num_labels, num_genres)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I6jbF2S2ZKWi",
        "outputId": "f8f680a5-2652-4618-bd54-314ff3396e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_76 (Dense)            (None, 256)               4608      \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 13)                845       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,605\n",
            "Trainable params: 46,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "75/75 - 1s - loss: 1.4795 - accuracy: 0.6517 - val_loss: 1.2242 - val_accuracy: 0.7073 - 1s/epoch - 19ms/step\n",
            "Epoch 2/50\n",
            "75/75 - 0s - loss: 1.2922 - accuracy: 0.7079 - val_loss: 1.2103 - val_accuracy: 0.7073 - 261ms/epoch - 3ms/step\n",
            "Epoch 3/50\n",
            "75/75 - 0s - loss: 1.2705 - accuracy: 0.7100 - val_loss: 1.2042 - val_accuracy: 0.7073 - 266ms/epoch - 4ms/step\n",
            "Epoch 4/50\n",
            "75/75 - 0s - loss: 1.2580 - accuracy: 0.7108 - val_loss: 1.2093 - val_accuracy: 0.7073 - 225ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "75/75 - 0s - loss: 1.2412 - accuracy: 0.7112 - val_loss: 1.2048 - val_accuracy: 0.7073 - 230ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "75/75 - 0s - loss: 1.2301 - accuracy: 0.7112 - val_loss: 1.2041 - val_accuracy: 0.7073 - 266ms/epoch - 4ms/step\n",
            "Epoch 7/50\n",
            "75/75 - 0s - loss: 1.2297 - accuracy: 0.7112 - val_loss: 1.2051 - val_accuracy: 0.7073 - 226ms/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "75/75 - 0s - loss: 1.2233 - accuracy: 0.7112 - val_loss: 1.2045 - val_accuracy: 0.7073 - 223ms/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "75/75 - 0s - loss: 1.2159 - accuracy: 0.7112 - val_loss: 1.2055 - val_accuracy: 0.7073 - 229ms/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "75/75 - 0s - loss: 1.2048 - accuracy: 0.7112 - val_loss: 1.2040 - val_accuracy: 0.7073 - 273ms/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "75/75 - 0s - loss: 1.2080 - accuracy: 0.7112 - val_loss: 1.2033 - val_accuracy: 0.7073 - 256ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "75/75 - 0s - loss: 1.2145 - accuracy: 0.7112 - val_loss: 1.2016 - val_accuracy: 0.7073 - 267ms/epoch - 4ms/step\n",
            "Epoch 13/50\n",
            "75/75 - 0s - loss: 1.2148 - accuracy: 0.7112 - val_loss: 1.2033 - val_accuracy: 0.7073 - 226ms/epoch - 3ms/step\n",
            "Epoch 14/50\n",
            "75/75 - 0s - loss: 1.2053 - accuracy: 0.7112 - val_loss: 1.2014 - val_accuracy: 0.7073 - 263ms/epoch - 4ms/step\n",
            "Epoch 15/50\n",
            "75/75 - 0s - loss: 1.2028 - accuracy: 0.7112 - val_loss: 1.2007 - val_accuracy: 0.7073 - 261ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "75/75 - 0s - loss: 1.1921 - accuracy: 0.7112 - val_loss: 1.1981 - val_accuracy: 0.7073 - 259ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "75/75 - 0s - loss: 1.1993 - accuracy: 0.7112 - val_loss: 1.2002 - val_accuracy: 0.7073 - 224ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "75/75 - 0s - loss: 1.1930 - accuracy: 0.7112 - val_loss: 1.1979 - val_accuracy: 0.7073 - 271ms/epoch - 4ms/step\n",
            "Epoch 19/50\n",
            "75/75 - 0s - loss: 1.1951 - accuracy: 0.7112 - val_loss: 1.1992 - val_accuracy: 0.7073 - 224ms/epoch - 3ms/step\n",
            "Epoch 20/50\n",
            "75/75 - 0s - loss: 1.1894 - accuracy: 0.7112 - val_loss: 1.1987 - val_accuracy: 0.7073 - 217ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "75/75 - 0s - loss: 1.1812 - accuracy: 0.7112 - val_loss: 1.2025 - val_accuracy: 0.7073 - 224ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "75/75 - 0s - loss: 1.1768 - accuracy: 0.7112 - val_loss: 1.1953 - val_accuracy: 0.7073 - 260ms/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "75/75 - 0s - loss: 1.1821 - accuracy: 0.7112 - val_loss: 1.1973 - val_accuracy: 0.7073 - 219ms/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "75/75 - 0s - loss: 1.1838 - accuracy: 0.7112 - val_loss: 1.1948 - val_accuracy: 0.7073 - 260ms/epoch - 3ms/step\n",
            "Epoch 25/50\n",
            "75/75 - 0s - loss: 1.1804 - accuracy: 0.7112 - val_loss: 1.1976 - val_accuracy: 0.7073 - 223ms/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "75/75 - 0s - loss: 1.1825 - accuracy: 0.7112 - val_loss: 1.2025 - val_accuracy: 0.7073 - 223ms/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "75/75 - 0s - loss: 1.1815 - accuracy: 0.7112 - val_loss: 1.1966 - val_accuracy: 0.7073 - 223ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "75/75 - 0s - loss: 1.1748 - accuracy: 0.7112 - val_loss: 1.1971 - val_accuracy: 0.7073 - 227ms/epoch - 3ms/step\n",
            "Epoch 29/50\n",
            "75/75 - 0s - loss: 1.1665 - accuracy: 0.7112 - val_loss: 1.1977 - val_accuracy: 0.7073 - 223ms/epoch - 3ms/step\n",
            "WARNING:tensorflow:6 out of the last 30 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002429B9D96C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "(1, 17)\n",
            "predictions: \n",
            "[[0.008 0.673 0.004 0.078 0.032 0.09  0.034 0.015 0.034 0.009 0.003 0.002\n",
            "  0.018]]\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 1.2011 - accuracy: 0.6947\n",
            "Test Loss: 1.2011429071426392\n",
            "Test Accuracy: 0.6947236061096191\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder  \n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "    # First hidden layer with 256 units and ReLU activation\n",
        "    keras.layers.Dense(256, input_shape=(training_features.shape[1],), activation='sigmoid'), # try relu and sigmoid\n",
        "    keras.layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    \n",
        "    # Second hidden layer with 128 units and ReLU activation\n",
        "    keras.layers.Dense(128, activation='sigmoid'),\n",
        "    keras.layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    \n",
        "    # Third hidden layer with 64 units and ReLU activation\n",
        "    keras.layers.Dense(64, activation='sigmoid'),\n",
        "    keras.layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    \n",
        "    # Output layer with num_classes units and softmax activation for multi-class classification\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print a summary of the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "optimizer=\"adam\": The optimizer algorithm to use during training. \n",
        "Adam optimizer is chosen, which is a popular optimization algorithm known for its efficiency.\n",
        "\n",
        "loss='categorical_crossentropy': The loss function used to measure the discrepancy between the \n",
        "predicted output and the true output labels. Categorical cross-entropy is suitable for\n",
        "multi-class classification tasks.\n",
        "\n",
        "metrics=['accuracy']: The metric(s) to be evaluated during training and testing. \n",
        "Accuracy is a commonly used metric to assess the model's performance.\n",
        "\"\"\"\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Encode the training and validation labels using one-hot encoding\n",
        "train_labels_encoded = to_categorical(training_labels)\n",
        "val_labels_encoded = to_categorical(validation_labels)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "training_features, train_labels_encoded: Input features and corresponding labels for model training.\n",
        "\n",
        "validation_features, val_labels_encoded: Validation set used to monitor the model's performance \n",
        "                                         during training.\n",
        "\n",
        "batch_size=32: Number of samples per gradient update. Training data is divided into batches, \n",
        "               and the model's weights are updated after each batch.\n",
        "\n",
        "epochs=50: Number of times the model will iterate over the entire training dataset.\n",
        "\n",
        "callbacks: EarlyStopping to stop training if the validation loss does not improve for a certain \n",
        "           number of epochs, and ModelCheckpoint to save the best model based on validation loss.\n",
        "\"\"\"\n",
        "history = model.fit(training_features, train_labels_encoded, \n",
        "                    validation_data=(validation_features, val_labels_encoded),\n",
        "                    batch_size=32, epochs=50, verbose=2,\n",
        "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
        "                               keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)])\n",
        "\n",
        "# Save the entire model to an h5 file\n",
        "model.save(\"my_model.h5\")\n",
        "\n",
        "# Optionally save the entire model as a pickle file\n",
        "with open('my_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "\n",
        "# Optionally load the pickled model from file\n",
        "with open('my_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Use the loaded model for prediction\n",
        "preds = model.predict(test_features[:1])\n",
        "print(test_features[:1].shape)\n",
        "\n",
        "print(\"predictions: \")\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)\n",
        "print(preds)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_features, to_categorical(test_labels))\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('matched_midi.pkl', 'rb') as f:\n",
        "    matched_midi_df = pickle.load(f)\n",
        "\n",
        "with open('labeled_features.pkl', 'rb') as f:\n",
        "    labeled_features = pickle.load(f)\n",
        "\n",
        "with open('my_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classify A New MIDI File Using NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "[[0.008 0.581 0.004 0.154 0.037 0.075 0.031 0.015 0.048 0.01  0.003 0.003\n",
            "  0.031]]\n",
            "Country\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pretty_midi\n",
        "\n",
        "def normalize_features(features):\n",
        "    \"\"\"\n",
        "    Normalizes the features to the range [-1, 1].\n",
        "\n",
        "    Parameters:\n",
        "        features (list of float): The array of features.\n",
        "\n",
        "    Returns:\n",
        "        list of float: Normalized features.\n",
        "    \"\"\"\n",
        "    # Normalize each feature based on its specific range\n",
        "    tempo = (features[0] - 150) / 300\n",
        "    num_sig_changes = (features[1] - 2) / 10\n",
        "    resolution = (features[2] - 260) / 400\n",
        "    time_sig_1 = (features[3] - 3) / 8\n",
        "    time_sig_2 = (features[4] - 3) / 8\n",
        "    melody_complexity = (features[5] - 0) / 10\n",
        "    melody_range = (features[6] - 0) / 80\n",
        "\n",
        "    # Normalize pitch class histogram\n",
        "    pitch_class_hist = [((f - 0) / 100) for f in features[7:-1]]\n",
        "\n",
        "    # Return the normalized feature vector\n",
        "    return [tempo, resolution, time_sig_1, time_sig_2, melody_complexity, melody_range] + pitch_class_hist\n",
        "\n",
        "def get_features(path):\n",
        "    \"\"\"\n",
        "    Extracts specific features from a MIDI file given its path using the pretty_midi library.\n",
        "    Handle any potential errors with MIDI files appropriately.\n",
        "\n",
        "    Parameters:\n",
        "        path (str): The path to the MIDI file.\n",
        "\n",
        "    Returns:\n",
        "        list of float: The extracted features.\n",
        "    \"\"\"\n",
        "    # Creates a PrettyMIDI object by loading the MIDI file specified by the given path.\n",
        "    file = pretty_midi.PrettyMIDI(path)\n",
        "    \n",
        "    # tempo: the estimated tempo of the audio file\n",
        "    tempo = file.estimate_tempo()\n",
        "\n",
        "    # num_sig_changes: the number of time signature changes in the audio file\n",
        "    num_sig_changes = len(file.time_signature_changes)\n",
        "\n",
        "    # resolution: the time resolution of the audio file (in ticks per beat)\n",
        "    resolution = file.resolution\n",
        "\n",
        "\n",
        "    # Extract time signature information\n",
        "    ts_changes = file.time_signature_changes\n",
        "    ts_1, ts_2 = 4, 4\n",
        "    if len(ts_changes) > 0:\n",
        "        ts_1 = ts_changes[0].numerator\n",
        "        ts_2 = ts_changes[0].denominator\n",
        "    \n",
        "    # Extract melody-related features\n",
        "    # melody: a pitch class histogram of the audio file\n",
        "    melody = file.get_pitch_class_histogram()\n",
        "    # melody_complexity: the number of unique pitch classes in the melody\n",
        "    melody_complexity = np.sum(melody > 0)\n",
        "    # melody_range: the range of pitch classes in the melody\n",
        "    melody_range = np.max(melody) - np.min(melody)\n",
        "    # OPTIONAL feature melody_contour: the temporal evolution of pitch content in the audio file\n",
        "    # melody_contour = librosa.feature.tempogram(y=file.fluidsynth(fs=16000), sr=16000, hop_length=512)\n",
        "    # melody_contour = np.mean(melody_contour, axis=0)\n",
        "    # chroma: a chroma representation of the audio file\n",
        "    chroma = file.get_chroma()\n",
        "    # pitch_class_hist: the sum of the chroma matrix along the pitch axis\n",
        "    pitch_class_hist = np.sum(chroma, axis=1)\n",
        "\n",
        "    return normalize_features([tempo, num_sig_changes, resolution, ts_1,\n",
        "                    ts_2, melody_complexity, melody_range] + list(pitch_class_hist)) # + list(melody_contour))\n",
        "    \n",
        "midi_path = \"test.mid\"\n",
        "midi_features = np.asarray(get_features(midi_path))\n",
        "midi_features = np.expand_dims(midi_features, axis = 0)\n",
        "\n",
        "prediction = model.predict(midi_features)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "genre = np.argmax(prediction)\n",
        "print(label_list[genre])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
